{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useEffect, useRef, useState } from 'react';\nexport const useAudioAnalyzer = onAudioLevel => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [audioLevel, setAudioLevel] = useState(0);\n  const audioContextRef = useRef(null);\n  const analyzerRef = useRef(null);\n  const microphoneRef = useRef(null);\n  const dataArrayRef = useRef(null);\n  const animationFrameRef = useRef(null);\n  const startListening = async () => {\n    try {\n      var _audioContextRef$curr;\n      if (((_audioContextRef$curr = audioContextRef.current) === null || _audioContextRef$curr === void 0 ? void 0 : _audioContextRef$curr.state) === 'suspended') {\n        await audioContextRef.current.resume();\n      }\n      if (!audioContextRef.current) {\n        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      }\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      microphoneRef.current = audioContextRef.current.createMediaStreamSource(stream);\n      analyzerRef.current = audioContextRef.current.createAnalyser();\n      analyzerRef.current.fftSize = 256;\n      analyzerRef.current.smoothingTimeConstant = 0.8;\n      microphoneRef.current.connect(analyzerRef.current);\n      const bufferLength = analyzerRef.current.frequencyBinCount;\n      dataArrayRef.current = new Uint8Array(bufferLength);\n      setIsListening(true);\n      analyzeAudio();\n    } catch (error) {\n      console.error('Error accessing microphone:', error);\n    }\n  };\n  const stopListening = () => {\n    if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n    if (microphoneRef.current) {\n      microphoneRef.current.disconnect();\n      microphoneRef.current = null;\n    }\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n    setIsListening(false);\n    setAudioLevel(0);\n  };\n  const analyzeAudio = () => {\n    if (!analyzerRef.current || !dataArrayRef.current) return;\n    analyzerRef.current.getByteFrequencyData(dataArrayRef.current);\n\n    // Calculate average volume\n    const average = dataArrayRef.current.reduce((sum, value) => sum + value, 0) / dataArrayRef.current.length;\n    const normalizedLevel = Math.min(average / 128, 1); // Normalize to 0-1\n\n    setAudioLevel(normalizedLevel);\n    if (onAudioLevel) {\n      onAudioLevel(normalizedLevel);\n    }\n    animationFrameRef.current = requestAnimationFrame(analyzeAudio);\n  };\n  useEffect(() => {\n    return () => {\n      stopListening();\n    };\n  }, []);\n  return {\n    startListening,\n    stopListening,\n    isListening,\n    audioLevel\n  };\n};\n_s(useAudioAnalyzer, \"9OiioOpahh8Y3WXIZLKJfOKWTxc=\");","map":{"version":3,"names":["useEffect","useRef","useState","useAudioAnalyzer","onAudioLevel","_s","isListening","setIsListening","audioLevel","setAudioLevel","audioContextRef","analyzerRef","microphoneRef","dataArrayRef","animationFrameRef","startListening","_audioContextRef$curr","current","state","resume","window","AudioContext","webkitAudioContext","stream","navigator","mediaDevices","getUserMedia","audio","createMediaStreamSource","createAnalyser","fftSize","smoothingTimeConstant","connect","bufferLength","frequencyBinCount","Uint8Array","analyzeAudio","error","console","stopListening","cancelAnimationFrame","disconnect","close","getByteFrequencyData","average","reduce","sum","value","length","normalizedLevel","Math","min","requestAnimationFrame"],"sources":["C:/Users/Krish/jarvis/web_gui/src/components/AudioAnalyzer.jsx"],"sourcesContent":["import { useEffect, useRef, useState } from 'react';\r\n\r\nexport const useAudioAnalyzer = (onAudioLevel) => {\r\n  const [isListening, setIsListening] = useState(false);\r\n  const [audioLevel, setAudioLevel] = useState(0);\r\n  const audioContextRef = useRef(null);\r\n  const analyzerRef = useRef(null);\r\n  const microphoneRef = useRef(null);\r\n  const dataArrayRef = useRef(null);\r\n  const animationFrameRef = useRef(null);\r\n\r\n  const startListening = async () => {\r\n    try {\r\n      if (audioContextRef.current?.state === 'suspended') {\r\n        await audioContextRef.current.resume();\r\n      }\r\n\r\n      if (!audioContextRef.current) {\r\n        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n      }\r\n\r\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n      microphoneRef.current = audioContextRef.current.createMediaStreamSource(stream);\r\n      analyzerRef.current = audioContextRef.current.createAnalyser();\r\n      \r\n      analyzerRef.current.fftSize = 256;\r\n      analyzerRef.current.smoothingTimeConstant = 0.8;\r\n      \r\n      microphoneRef.current.connect(analyzerRef.current);\r\n      \r\n      const bufferLength = analyzerRef.current.frequencyBinCount;\r\n      dataArrayRef.current = new Uint8Array(bufferLength);\r\n      \r\n      setIsListening(true);\r\n      analyzeAudio();\r\n    } catch (error) {\r\n      console.error('Error accessing microphone:', error);\r\n    }\r\n  };\r\n\r\n  const stopListening = () => {\r\n    if (animationFrameRef.current) {\r\n      cancelAnimationFrame(animationFrameRef.current);\r\n    }\r\n    \r\n    if (microphoneRef.current) {\r\n      microphoneRef.current.disconnect();\r\n      microphoneRef.current = null;\r\n    }\r\n    \r\n    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\r\n      audioContextRef.current.close();\r\n      audioContextRef.current = null;\r\n    }\r\n    \r\n    setIsListening(false);\r\n    setAudioLevel(0);\r\n  };\r\n\r\n  const analyzeAudio = () => {\r\n    if (!analyzerRef.current || !dataArrayRef.current) return;\r\n\r\n    analyzerRef.current.getByteFrequencyData(dataArrayRef.current);\r\n    \r\n    // Calculate average volume\r\n    const average = dataArrayRef.current.reduce((sum, value) => sum + value, 0) / dataArrayRef.current.length;\r\n    const normalizedLevel = Math.min(average / 128, 1); // Normalize to 0-1\r\n    \r\n    setAudioLevel(normalizedLevel);\r\n    \r\n    if (onAudioLevel) {\r\n      onAudioLevel(normalizedLevel);\r\n    }\r\n\r\n    animationFrameRef.current = requestAnimationFrame(analyzeAudio);\r\n  };\r\n\r\n  useEffect(() => {\r\n    return () => {\r\n      stopListening();\r\n    };\r\n  }, []);\r\n\r\n  return {\r\n    startListening,\r\n    stopListening,\r\n    isListening,\r\n    audioLevel\r\n  };\r\n};\r\n"],"mappings":";AAAA,SAASA,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAEnD,OAAO,MAAMC,gBAAgB,GAAIC,YAAY,IAAK;EAAAC,EAAA;EAChD,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGL,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACM,UAAU,EAAEC,aAAa,CAAC,GAAGP,QAAQ,CAAC,CAAC,CAAC;EAC/C,MAAMQ,eAAe,GAAGT,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMU,WAAW,GAAGV,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMW,aAAa,GAAGX,MAAM,CAAC,IAAI,CAAC;EAClC,MAAMY,YAAY,GAAGZ,MAAM,CAAC,IAAI,CAAC;EACjC,MAAMa,iBAAiB,GAAGb,MAAM,CAAC,IAAI,CAAC;EAEtC,MAAMc,cAAc,GAAG,MAAAA,CAAA,KAAY;IACjC,IAAI;MAAA,IAAAC,qBAAA;MACF,IAAI,EAAAA,qBAAA,GAAAN,eAAe,CAACO,OAAO,cAAAD,qBAAA,uBAAvBA,qBAAA,CAAyBE,KAAK,MAAK,WAAW,EAAE;QAClD,MAAMR,eAAe,CAACO,OAAO,CAACE,MAAM,CAAC,CAAC;MACxC;MAEA,IAAI,CAACT,eAAe,CAACO,OAAO,EAAE;QAC5BP,eAAe,CAACO,OAAO,GAAG,KAAKG,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MACpF;MAEA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzEf,aAAa,CAACK,OAAO,GAAGP,eAAe,CAACO,OAAO,CAACW,uBAAuB,CAACL,MAAM,CAAC;MAC/EZ,WAAW,CAACM,OAAO,GAAGP,eAAe,CAACO,OAAO,CAACY,cAAc,CAAC,CAAC;MAE9DlB,WAAW,CAACM,OAAO,CAACa,OAAO,GAAG,GAAG;MACjCnB,WAAW,CAACM,OAAO,CAACc,qBAAqB,GAAG,GAAG;MAE/CnB,aAAa,CAACK,OAAO,CAACe,OAAO,CAACrB,WAAW,CAACM,OAAO,CAAC;MAElD,MAAMgB,YAAY,GAAGtB,WAAW,CAACM,OAAO,CAACiB,iBAAiB;MAC1DrB,YAAY,CAACI,OAAO,GAAG,IAAIkB,UAAU,CAACF,YAAY,CAAC;MAEnD1B,cAAc,CAAC,IAAI,CAAC;MACpB6B,YAAY,CAAC,CAAC;IAChB,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;IACrD;EACF,CAAC;EAED,MAAME,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIzB,iBAAiB,CAACG,OAAO,EAAE;MAC7BuB,oBAAoB,CAAC1B,iBAAiB,CAACG,OAAO,CAAC;IACjD;IAEA,IAAIL,aAAa,CAACK,OAAO,EAAE;MACzBL,aAAa,CAACK,OAAO,CAACwB,UAAU,CAAC,CAAC;MAClC7B,aAAa,CAACK,OAAO,GAAG,IAAI;IAC9B;IAEA,IAAIP,eAAe,CAACO,OAAO,IAAIP,eAAe,CAACO,OAAO,CAACC,KAAK,KAAK,QAAQ,EAAE;MACzER,eAAe,CAACO,OAAO,CAACyB,KAAK,CAAC,CAAC;MAC/BhC,eAAe,CAACO,OAAO,GAAG,IAAI;IAChC;IAEAV,cAAc,CAAC,KAAK,CAAC;IACrBE,aAAa,CAAC,CAAC,CAAC;EAClB,CAAC;EAED,MAAM2B,YAAY,GAAGA,CAAA,KAAM;IACzB,IAAI,CAACzB,WAAW,CAACM,OAAO,IAAI,CAACJ,YAAY,CAACI,OAAO,EAAE;IAEnDN,WAAW,CAACM,OAAO,CAAC0B,oBAAoB,CAAC9B,YAAY,CAACI,OAAO,CAAC;;IAE9D;IACA,MAAM2B,OAAO,GAAG/B,YAAY,CAACI,OAAO,CAAC4B,MAAM,CAAC,CAACC,GAAG,EAAEC,KAAK,KAAKD,GAAG,GAAGC,KAAK,EAAE,CAAC,CAAC,GAAGlC,YAAY,CAACI,OAAO,CAAC+B,MAAM;IACzG,MAAMC,eAAe,GAAGC,IAAI,CAACC,GAAG,CAACP,OAAO,GAAG,GAAG,EAAE,CAAC,CAAC,CAAC,CAAC;;IAEpDnC,aAAa,CAACwC,eAAe,CAAC;IAE9B,IAAI7C,YAAY,EAAE;MAChBA,YAAY,CAAC6C,eAAe,CAAC;IAC/B;IAEAnC,iBAAiB,CAACG,OAAO,GAAGmC,qBAAqB,CAAChB,YAAY,CAAC;EACjE,CAAC;EAEDpC,SAAS,CAAC,MAAM;IACd,OAAO,MAAM;MACXuC,aAAa,CAAC,CAAC;IACjB,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,OAAO;IACLxB,cAAc;IACdwB,aAAa;IACbjC,WAAW;IACXE;EACF,CAAC;AACH,CAAC;AAACH,EAAA,CAvFWF,gBAAgB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}